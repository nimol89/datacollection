
<!-- saved from url=(0035)https://diffusion-vision.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- from MDCA -->
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="author" content="Nimol Thuon">
    <meta name="description"
        content="Multimodal Understanding: SYLLABLE ANALYSIS AUGMENTATION STRANGY IN PALM-LEAF PROJECT">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

    <title>Data collection in Palm Leaf Manuscripts. </title>
    <!-- <link rel="icon" href="iitd_logo.png" type="image/png"> -->
    <link rel="icon" href="" type="image/png">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <link type="text/css" rel="stylesheet" href="./css/main.css">
    <link rel="preconnect" href="https://fonts.googleapis.com/">
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="">
    <link rel="stylesheet" href="./css/css2">
    <style>
        .title {
          color: black; /* Set default color */
        }
      
        .gray-text {
          color: #828282; /* Use your desired shade of grey */
          /* Bold*/
          font-weight: bold;
        }
        .gray-text2 {
          color: #515151; /* Use your desired shade of grey */
          /* Bold*/
          font-weight: bold;
        }
        .author {
            color: #088df3; /* Use your desired shade of grey */
        }
        .affiliations2 {
            color: #7d7d7d; /* Use your desired shade of grey */
            text-align: center;
            font-size: smaller;
        }
        .affiliations {
            font-size: larger;
        }
        .logo {
            position: fixed;
        }
        .logo img {
            position: fixed;
            width: 90px; /* Adjust the width as needed */
            height: auto; /* Maintain aspect ratio */
            top: 10px; /* Adjust as needed */
            right: 10px; /* Adjust as needed */
            z-index: 999; /* Ensure the logo appears on top of other content */
            
        }
        .center {
            text-align: center;
        }
        .bigger-font {
            font-size: 24px; /* Adjust the font size as needed */
        }
        .bold-text {
            font-weight: bold;
        }
        .left-align {
            text-align: left;
        }
        .font-size-author-names {
            font-size: 21px;
        }
        .center-align {
            text-align: center;
        }
        .section{
            font-size: 150%;
            font-weight: 500;
            /* background: rgba(0,0,0,0.03); */
            padding-top: 0.5em;
            padding-bottom: 0.5em;
            color: #565656;
            text-align: center;
            /* padding-left: 0.5em; */
        }
      </style>
    </head>
    
<body data-new-gr-c-s-check-loaded="14.1162.0" data-gr-ext-installed="">
    <div class="container">
    <!-- <div class="BbxBP a3ETed K5Zlne" jsname="WA9qLc" jscontroller="RQOkef" jsaction="rcuQ6b:ywL4Jf;VbOlFf:ywL4Jf;FaOgy:ywL4Jf; keydown:Hq2uPe; wheel:Ut4Ahc;" data-top-navigation="true" data-is-preview="true"></div> -->
<!--     <div class="logo">
        <img src="" alt="Logo">
    </div> -->
    <p class="title"><span class="gray-text">Data collection in Palm Leaf Manuscripts. </p>
    <p class="gray-text2 center bigger-font">ICFHR 2022</p>
    <!-- <p class="title">Effective Conditioning of Diffusion Models for Monocular Depth Estimation</p> -->

    <p class="author">
        <span class="author font-size-author-names">
            <a href="">
            Nimol&nbsp;Thuon*</a>
        </span>
        <span class="author font-size-author-names">
            <a href="">
                Jun&nbsp;Du*</a>
        </span>
             <span class="author font-size-author-names">
            <a href="">
                Sokpheak&nbsp;Tan</a>
        </span>
                     <span class="author font-size-author-names">
            <a href="">
                Lymeng&nbsp;Phat</a>
        </span>
                             <span class="author font-size-author-names">
            <a href="">
                Sada&nbsp;Thuon</a>
        </span>
                                     <span class="author font-size-author-names">
            <a href="">
                Panhapin&nbsp;Theang</a>
        </span>
                                             <span class="author font-size-author-names">
            <a href="">
                Chan Theara&nbsp;Sok</a>
        </span>
                                                     <span class="author font-size-author-names">
            <a href="">
                Reaksa&nbsp;Phea</a>
        </span>
                                                             <span class="author font-size-author-names">
            <a href="">
                MD&nbsp;Kazy</a>
        </span>
                                                                  <span class="author font-size-author-names">
            <a href="">
                Ranysakol&nbsp;Thuon</a>
        </span>
 
 
    </p>
    <div class="affiliations">
        <!-- <a href="https://home.iitd.ac.in/"> -->
            1. University of Science and Technology of China,  China


        <!-- </a> -->
    </div>
        <div class="affiliations">
        <!-- <a href="https://home.iitd.ac.in/"> -->
           2. Institue of Technology of Cambodia, Cambodia


        <!-- </a> -->
    </div>
            <div class="affiliations">
        <!-- <a href="https://home.iitd.ac.in/"> -->
           3. Universitas Gadjah Mada, Indonesia


        <!-- </a> -->
    </div>

    <p class="section center">Project Descriptions</p>
    <p>
 
   The digitization of ancient palm leaf manuscripts is gaining traction due to challenges like limited datasets and complex text features. Previous studies have not thoroughly explored the application of advanced techniques on these manuscripts, particularly as deep learning approaches require large datasets. This paper investigates methods to enhance isolated glyph classification by focusing on both front-end and back-end processes. On the front end, we present multi-task preprocessing techniques, including data augmentation and image enhancement, to improve dataset quality and quantity. On the back end, we analyze visual backbones of deep learning models, such as CNNs (VGG, ResNet, EfficientNet) and attention-based models (ViT, DeiT, CvT). Our evaluation assesses the interaction between data augmentation and training data volume. We conducted experiments on Balinese, Sundanese, and Khmer scripts from the ICFHR 2018 contest, demonstrating effective training methods for the document analysis community.



    </p>
    <div class="flex-container margin-top-1em margin-bottom-1em">
        <figure>
        <img src="./assets/1.JPG">



</figcaption>
        </figure>
    </div>  
        <div class="flex-container margin-top-1em margin-bottom-1em">
        <figure>
        <img src="./assets/2.JPG">



</figcaption>
        </figure>
    </div>  
<h2>Challenges Faced</h2>
<p>During the data extraction process, several challenges emerged that required strategic solutions:</p>

<ul>
    <li><strong>Limited Dataset Diversity:</strong><br>
    The existing datasets for palm leaf manuscripts are often limited in both size and diversity, making it difficult to train robust machine learning models. Our approach aimed to mitigate this by actively seeking additional sources, but acquiring high-quality images remains a challenge.</li>

    <li><strong>Complex Character Recognition:</strong><br>
    The intricate nature of palm leaf scripts, including layered characters and varying text quality, complicates the segmentation and labeling process. Ensuring accurate identification of isolated glyphs requires extensive knowledge and careful attention to detail.</li>

    <li><strong>Variability in Manuscript Quality:</strong><br>
    The quality of scanned manuscripts can vary significantly, with some images being degraded due to age, damage, or poor scanning practices. This inconsistency poses difficulties in preprocessing and may affect the effectiveness of our image enhancement techniques.</li>

    <li><strong>Collaboration and Training:</strong><br>
    While the involvement of students adds value, it also necessitates comprehensive training to ensure they understand the nuances of character classification and labeling. Coordinating efforts between the two groups (collectors and validators) requires effective communication and iterative feedback to maintain quality control.</li>

    <li><strong>Validation Complexity:</strong><br>
    Validating the labels against existing dictionaries and character classes can be time-consuming, particularly when discrepancies arise. Establishing a reliable method for resolving conflicts in labeling is essential for data integrity.</li>
</ul>

<p>Addressing these challenges is crucial for the success of our project and the overall quality of the extracted datasets. By continuously refining our processes and leveraging the expertise of our participants, we aim to overcome these obstacles and enhance the digitization of palm leaf manuscripts.</p>

    <h1>Data Extraction Process for Palm Leaf Manuscripts</h1>
    
    <h2>1. Objective</h2>
    <p>In this step, we aim to extract new collections based on the text-line and word datasets [10]. The existing publicly available datasets of isolated glyph images are limited in size and variety. To address this issue, we will enhance our dataset by extracting additional images from prior works featuring three key manuscripts, specifically targeting the complexities and unique features of palm leaf manuscripts.</p>
    
    <h2>2. Participant Selection</h2>
    <p>To ensure the quality and accuracy of our data extraction and labeling, we selected 15 local university students from Southeast Asia. Their comprehensive knowledge of the Cambodian and Indonesian languages is invaluable for our experiment’s classification and labeling process. These students volunteered for this project, demonstrating their interest in historical linguistics and document analysis, which enhances the project's credibility.</p>
    
    <h2>3. Data Collection Process</h2>
    <p>As illustrated in Fig. 1, we manually crop and label the images using user-friendly annotation tools designed for efficiency and accuracy. The 15 students are divided into two distinct groups to streamline the data collection process:</p>
    
    <ul>
        <li><strong>Group 1: Collectors</strong><br>
        This group is tasked with extracting and identifying characters from the palm leaf images. Utilizing their general knowledge, they segment and label these images based on varying qualities of text and resolutions. The collectors are trained on the characteristics of the glyphs, allowing them to recognize subtle differences that are crucial for accurate classification.</li>
        
        <li><strong>Group 2: Validators</strong><br>
        This group is responsible for validating the labels assigned by the collectors. They cross-reference the extracted characters against established character classes and dictionaries from [10] to ensure accuracy. This validation process is critical for maintaining high data quality and involves iterative feedback sessions where validators review the collectors' work to correct any inconsistencies.</li>
    </ul>
    
    <h2>4. Data Annotation Tools</h2>
    <p>We utilized advanced annotation tools that facilitate the labeling process through intuitive interfaces. These tools allow users to easily crop images, label characters, and save their work efficiently. The annotations are crucial for training machine learning models, ensuring that each character is accurately represented within the dataset.</p>
    
    <h2>5. Results</h2>
    <p>As a result of this collaborative effort, we successfully collected 15,000 images from the palm leaf datasets. Our goal is to increase the original datasets by 20–50%, particularly focusing on small datasets like the Sundanese and Balinese manuscripts. This expansion will significantly enhance the training capabilities of our deep learning models, ultimately improving the recognition and classification of isolated glyphs.</p>
    
    <h2>6. Future Directions</h2>
    <p>The successful collection and validation of these images mark a significant step forward in the digitization of palm leaf manuscripts. Future work will focus on integrating this expanded dataset into our deep learning frameworks, allowing for more robust model training and improved classification accuracy. Additionally, we plan to explore the application of various data augmentation techniques to further enrich our datasets and enhance model performance.</p>
    
    <h2>7. Conclusion</h2>
    <p>This project not only aims to enhance the datasets for isolated glyph classification but also contributes to the broader field of historical document analysis. By leveraging the expertise of local students and employing sophisticated data collection methods, we hope to make significant advancements in the recognition and preservation of palm leaf manuscripts.</p>


    
</div>
</body>
</html>
